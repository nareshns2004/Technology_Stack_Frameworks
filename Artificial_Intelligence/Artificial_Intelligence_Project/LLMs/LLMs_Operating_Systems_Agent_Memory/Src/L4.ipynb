{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4e5f77a-6406-4d19-ac08-0cd968faf831",
   "metadata": {},
   "source": [
    "# Programming Agent Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63196bdb-3d82-497e-8ef6-630372823d0c",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b44ffa5-ea48-4bb9-8933-10cd30ac9d30",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> ðŸ’» &nbsp; <b>Access <code>requirements.txt</code> and <code>helper.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>.\n",
    "\n",
    "<p> â¬‡ &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
    "\n",
    "<p> ðŸ“’ &nbsp; For more help, please see the <em>\"Appendix â€“ Tips, Help, and Download\"</em> Lesson.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cc6632-f3d5-4ea3-8ee3-db85193912ae",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> ðŸš¨\n",
    "&nbsp; <b>Different Run Results:</b> The output generated by AI models can vary with each execution due to their dynamic, probabilistic nature. Your results may differ from those shown in the video.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6126f43f-eba6-4dce-9df5-c884fd4ffd19",
   "metadata": {},
   "source": [
    "Letta agents persist information over time and restarts by saving data to a database. These lessons do not require past information. To enable a clean restart, the database is cleared before starting the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3698ae50-4b95-4ab2-9438-0567cd64d2b4",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "!rm  -f ~/.letta/sqlite.db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b77cfcd-3155-4e60-bb01-3a4e1292863c",
   "metadata": {},
   "source": [
    "## Section 0: Setup a MemGPT client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d585ab9c-3ccc-4d26-980f-68e494e53336",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from helper import nb_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "137aa217-24bb-4372-b21c-37f21a945c9d",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Config:  /home/jovyan/.letta/config\n"
     ]
    }
   ],
   "source": [
    "from letta import create_client \n",
    "\n",
    "client = create_client() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5e108e4-bcf9-4be1-b2c0-66539cbe9ec3",
   "metadata": {
    "height": 76
   },
   "outputs": [],
   "source": [
    "from letta.schemas.llm_config import LLMConfig\n",
    "\n",
    "client.set_default_llm_config(LLMConfig.default_config(\"gpt-4o-mini\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c66c27-e5f4-407b-aeb1-d5ad4f063111",
   "metadata": {},
   "source": [
    "## Section 1: Memory Blocks "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b601a6-875c-4476-a6aa-68ad830b7bf6",
   "metadata": {},
   "source": [
    "### Understanding ChatMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a0e6729-0f02-497f-8f85-688ed4f65f68",
   "metadata": {
    "height": 42
   },
   "outputs": [],
   "source": [
    "from letta.schemas.memory import ChatMemory  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16bbb19b-2fa2-4cac-8803-5cb179c36d47",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "chat_memory = ChatMemory(\n",
    "    human=\"Name: Bob\", \n",
    "    persona=\"You are a helpful assistant\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ed0f467-c545-4b26-8a10-2cb009240b5a",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['persona', 'human']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_memory.list_block_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75cc6a09-6c24-4b45-8b92-6084acdc3d46",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Block(value='Name: Bob', limit=2000, name='human', template=False, label='human', description=None, metadata_={}, user_id=None, id='block-ab92862a-a2a0-4347-a195-1f05e5f7faf0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_memory.get_block(\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0e0b63a-b8e7-4958-8c81-71dce3328391",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d2cc3dd-0278-40f7-8c0e-e919cb628c31",
   "metadata": {
    "height": 42
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def core_memory_append(self: \"Agent\", name: str, content: str) -> Optional[str]:  # type: ignore\n",
      "        \"\"\"\n",
      "        Append to the contents of core memory.\n",
      "\n",
      "        Args:\n",
      "            name (str): Section of the memory to be edited (persona or human).\n",
      "            content (str): Content to write to the memory. All unicode (including emojis) are supported.\n",
      "\n",
      "        Returns:\n",
      "            Optional[str]: None is always returned as this function does not produce a response.\n",
      "        \"\"\"\n",
      "        current_value = str(self.memory.get_block(name).value)\n",
      "        new_value = current_value + \"\\n\" + str(content)\n",
      "        self.memory.update_block_value(name=name, value=new_value)\n",
      "        return None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(chat_memory.core_memory_append))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33374545-64f8-4f79-92b4-f6a80851336a",
   "metadata": {},
   "source": [
    "#### Context compilation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf728dce-f06b-4bcb-a3ba-15a7f099b2d9",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{% for block in memory.values() %}<{{ block.name }} characters=\"{{ block.value|length }}/{{ block.limit }}\">\\n{{ block.value }}\\n</{{ block.name }}>{% if not loop.last %}\\n{% endif %}{% endfor %}'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_memory.get_prompt_template()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de7b9f35-8599-4465-952a-b2db2d7b1533",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<persona characters=\"27/2000\">\\nYou are a helpful assistant\\n</persona>\\n<human characters=\"9/2000\">\\nName: Bob\\n</human>'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_memory.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f3b0de-e3ed-413c-852a-71efae8a591d",
   "metadata": {},
   "source": [
    "## Section 2: Defining a custom memory module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f41239-463e-4609-8870-cbbae06a8f3a",
   "metadata": {},
   "source": [
    "### Defining a memory module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76d419bd-020c-4f6f-81c3-e704d65f5306",
   "metadata": {
    "height": 93
   },
   "outputs": [],
   "source": [
    "from letta.schemas.memory import ChatMemory\n",
    "from letta.schemas.block import Block\n",
    "from typing import Optional, List\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2df27d7b-d2b6-4d87-90c3-6759a70fa8d7",
   "metadata": {
    "height": 841
   },
   "outputs": [],
   "source": [
    "class TaskMemory(ChatMemory): \n",
    "\n",
    "    def __init__(self, human: str, persona: str, tasks: List[str]): \n",
    "        super().__init__(human=human, persona=persona, limit=2000) \n",
    "        self.link_block(\n",
    "            name=\"tasks\", \n",
    "            block=Block(\n",
    "                limit=2000, \n",
    "                value=json.dumps(tasks), \n",
    "                name=\"tasks\", \n",
    "                label=\"tasks\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def task_queue_push(self: \"Agent\", task_description: str):\n",
    "        \"\"\"\n",
    "        Push to a task queue stored in core memory. \n",
    "\n",
    "        Args:\n",
    "            task_description (str): A description of the next task you must accomplish. \n",
    "            \n",
    "        Returns:\n",
    "            Optional[str]: None is always returned as this function \n",
    "            does not produce a response.\n",
    "        \"\"\"\n",
    "        import json\n",
    "        tasks = json.loads(self.memory.get_block(\"tasks\").value)\n",
    "        tasks.append(task_description)\n",
    "        self.memory.update_block_value(\"tasks\", json.dumps(tasks))\n",
    "        return None\n",
    "\n",
    "    def task_queue_pop(self: \"Agent\"):\n",
    "        \"\"\"\n",
    "        Get the next task from the task queue \n",
    " \n",
    "        Returns:\n",
    "            Optional[str]: The description of the task popped from the \n",
    "            queue, if there are still tasks in queue. Otherwise, returns\n",
    "            None (the task queue is empty)\n",
    "        \"\"\"\n",
    "        import json\n",
    "        tasks = json.loads(self.memory.get_block(\"tasks\").value)\n",
    "        if len(tasks) == 0: \n",
    "            return None\n",
    "        task = tasks[0]\n",
    "        print(\"CURRENT TASKS: \", tasks)\n",
    "        self.memory.update_block_value(\"tasks\", json.dumps(tasks[1:]))\n",
    "        return task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b534a35b-506b-44fc-b658-d213a7eed2f9",
   "metadata": {},
   "source": [
    "### Creating an agent with custom `TaskMemory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "571e53e5-4190-4787-9cb2-efc527885c2d",
   "metadata": {
    "height": 212
   },
   "outputs": [],
   "source": [
    "task_agent_name = \"task_agent\"\n",
    "\n",
    "task_agent_state = client.create_agent(\n",
    "    name=task_agent_name, \n",
    "    system = open(\"task_queue_system_prompt.txt\", \"r\").read(),\n",
    "    memory=TaskMemory(\n",
    "        human=\"My name is Sarah\", \n",
    "        persona=\"You are an agent that must clear its tasks.\", \n",
    "        tasks=[]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2534c3f7-55d9-4f5f-892c-82221ccd1b78",
   "metadata": {
    "height": 59
   },
   "outputs": [],
   "source": [
    "message = \"Add 'start calling me Charles'\"  \\\n",
    "+ \"and 'tell me a haiku about my name' as two seperate tasks.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85ddb91c-5d8c-4f1c-87fd-f8c2b75f7990",
   "metadata": {
    "height": 115
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TASKS:  ['start calling me Charles', 'tell me a haiku about my name']\n",
      "CURRENT TASKS:  ['tell me a haiku about my name']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .message-container {\n",
       "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
       "            max-width: 800px;\n",
       "            margin: 20px auto;\n",
       "            background-color: #1e1e1e;\n",
       "            border-radius: 8px;\n",
       "            overflow: hidden;\n",
       "            color: #d4d4d4;\n",
       "        }\n",
       "        .message {\n",
       "            padding: 10px 15px;\n",
       "            border-bottom: 1px solid #3a3a3a;\n",
       "        }\n",
       "        .message:last-child {\n",
       "            border-bottom: none;\n",
       "        }\n",
       "        .title {\n",
       "            font-weight: bold;\n",
       "            margin-bottom: 5px;\n",
       "            color: #ffffff;\n",
       "            text-transform: uppercase;\n",
       "            font-size: 0.9em;\n",
       "        }\n",
       "        .content {\n",
       "            background-color: #2d2d2d;\n",
       "            border-radius: 4px;\n",
       "            padding: 5px 10px;\n",
       "            font-family: 'Consolas', 'Courier New', monospace;\n",
       "            white-space: pre-wrap;\n",
       "        }\n",
       "        .status-line {\n",
       "            margin-bottom: 5px;\n",
       "            color: #d4d4d4;\n",
       "        }\n",
       "        .function-name { color: #569cd6; }\n",
       "        .json-key { color: #9cdcfe; }\n",
       "        .json-string { color: #ce9178; }\n",
       "        .json-number { color: #b5cea8; }\n",
       "        .json-boolean { color: #569cd6; }\n",
       "        .internal-monologue { font-style: italic; }\n",
       "    </style>\n",
       "    <div class=\"message-container\">\n",
       "    \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">INTERNAL MONOLOGUE</div>\n",
       "            <div class=\"content\"><span class=\"internal-monologue\">Received new tasks. Commencing task registration in the queue. Will return to conversation upon task registration completion.</span></div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">FUNCTION CALL</div>\n",
       "            <div class=\"content\"><span class=\"function-name\">task_queue_push</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"task_description\"</span>: <span class=\"json-key\">\"start calling me Charles\",<br>&nbsp;&nbsp;\"request_heartbeat\"</span>: <span class=\"json-boolean\">true</span><br>})</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">INTERNAL MONOLOGUE</div>\n",
       "            <div class=\"content\"><span class=\"internal-monologue\">First task registered successfully. Proceeding to register the second task.</span></div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">FUNCTION CALL</div>\n",
       "            <div class=\"content\"><span class=\"function-name\">task_queue_push</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"task_description\"</span>: <span class=\"json-key\">\"tell me a haiku about my name\",<br>&nbsp;&nbsp;\"request_heartbeat\"</span>: <span class=\"json-boolean\">true</span><br>})</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">INTERNAL MONOLOGUE</div>\n",
       "            <div class=\"content\"><span class=\"internal-monologue\">Task registration successful. With the queue populated, let&#x27;s move onto executing the tasks. Time to pop the first task from the queue.</span></div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">FUNCTION CALL</div>\n",
       "            <div class=\"content\"><span class=\"function-name\">task_queue_pop</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"request_heartbeat\"</span>: <span class=\"json-boolean\">true</span><br>})</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">FUNCTION RETURN</div>\n",
       "            <div class=\"content\">{<br>&nbsp;&nbsp;<span class=\"json-key\">\"status\"</span>: <span class=\"json-key\">\"OK\",<br>&nbsp;&nbsp;\"message\"</span>: <span class=\"json-key\">\"start calling me Charles\",<br>&nbsp;&nbsp;\"time\"</span>: <span class=\"json-string\">\"2025-01-15 05:52:55 PM UTC+0000\"</span><br>}</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">INTERNAL MONOLOGUE</div>\n",
       "            <div class=\"content\"><span class=\"internal-monologue\">First task retrieved: &quot;start calling me Charles&quot;. Proceeding to modify core memory to reflect the user&#x27;s new name preference.</span></div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">FUNCTION CALL</div>\n",
       "            <div class=\"content\"><span class=\"function-name\">core_memory_replace</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"name\"</span>: <span class=\"json-key\">\"human\",<br>&nbsp;&nbsp;\"old_content\"</span>: <span class=\"json-key\">\"My name is Sarah\",<br>&nbsp;&nbsp;\"new_content\"</span>: <span class=\"json-key\">\"My name is Charles\",<br>&nbsp;&nbsp;\"request_heartbeat\"</span>: <span class=\"json-boolean\">true</span><br>})</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">INTERNAL MONOLOGUE</div>\n",
       "            <div class=\"content\"><span class=\"internal-monologue\">Name change successful. Now, Charles, let&#x27;s proceed to the next task. Commencing task retrieval from queue.</span></div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">FUNCTION CALL</div>\n",
       "            <div class=\"content\"><span class=\"function-name\">task_queue_pop</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"request_heartbeat\"</span>: <span class=\"json-boolean\">true</span><br>})</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">FUNCTION RETURN</div>\n",
       "            <div class=\"content\">{<br>&nbsp;&nbsp;<span class=\"json-key\">\"status\"</span>: <span class=\"json-key\">\"OK\",<br>&nbsp;&nbsp;\"message\"</span>: <span class=\"json-key\">\"tell me a haiku about my name\",<br>&nbsp;&nbsp;\"time\"</span>: <span class=\"json-string\">\"2025-01-15 05:53:02 PM UTC+0000\"</span><br>}</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">INTERNAL MONOLOGUE</div>\n",
       "            <div class=\"content\"><span class=\"internal-monologue\">Second task retrieved: &quot;tell me a haiku about my name&quot;. Formulating a haiku about Charles.</span></div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">FUNCTION CALL</div>\n",
       "            <div class=\"content\"><span class=\"function-name\">send_message</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"message\"</span>: <span class=\"json-string\">\"In the heart of Charles,\\nSturdy as an age-old oak,\\nA tale unfolds slow.\"</span><br>})</div>\n",
       "        </div>\n",
       "        </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = client.send_message(\n",
    "    agent_id=task_agent_state.id, \n",
    "    role=\"user\", \n",
    "    message=message\n",
    ")\n",
    "nb_print(response.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7cc0a070-d3e5-4832-90af-99d3544862e2",
   "metadata": {
    "height": 115
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .message-container {\n",
       "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
       "            max-width: 800px;\n",
       "            margin: 20px auto;\n",
       "            background-color: #1e1e1e;\n",
       "            border-radius: 8px;\n",
       "            overflow: hidden;\n",
       "            color: #d4d4d4;\n",
       "        }\n",
       "        .message {\n",
       "            padding: 10px 15px;\n",
       "            border-bottom: 1px solid #3a3a3a;\n",
       "        }\n",
       "        .message:last-child {\n",
       "            border-bottom: none;\n",
       "        }\n",
       "        .title {\n",
       "            font-weight: bold;\n",
       "            margin-bottom: 5px;\n",
       "            color: #ffffff;\n",
       "            text-transform: uppercase;\n",
       "            font-size: 0.9em;\n",
       "        }\n",
       "        .content {\n",
       "            background-color: #2d2d2d;\n",
       "            border-radius: 4px;\n",
       "            padding: 5px 10px;\n",
       "            font-family: 'Consolas', 'Courier New', monospace;\n",
       "            white-space: pre-wrap;\n",
       "        }\n",
       "        .status-line {\n",
       "            margin-bottom: 5px;\n",
       "            color: #d4d4d4;\n",
       "        }\n",
       "        .function-name { color: #569cd6; }\n",
       "        .json-key { color: #9cdcfe; }\n",
       "        .json-string { color: #ce9178; }\n",
       "        .json-number { color: #b5cea8; }\n",
       "        .json-boolean { color: #569cd6; }\n",
       "        .internal-monologue { font-style: italic; }\n",
       "    </style>\n",
       "    <div class=\"message-container\">\n",
       "    \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">INTERNAL MONOLOGUE</div>\n",
       "            <div class=\"content\"><span class=\"internal-monologue\">Tasks seem to be complete. But let&#x27;s double-check for any remaining tasks in the queue.</span></div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">FUNCTION CALL</div>\n",
       "            <div class=\"content\"><span class=\"function-name\">task_queue_pop</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"request_heartbeat\"</span>: <span class=\"json-boolean\">true</span><br>})</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">INTERNAL MONOLOGUE</div>\n",
       "            <div class=\"content\"><span class=\"internal-monologue\">The task queue is indeed empty, hence all tasks are complete. Time to inform Charles about the completion.</span></div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">FUNCTION CALL</div>\n",
       "            <div class=\"content\"><span class=\"function-name\">send_message</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"message\"</span>: <span class=\"json-string\">\"I've completed all the tasks, Charles.\"</span><br>})</div>\n",
       "        </div>\n",
       "        </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = client.send_message(\n",
    "    agent_id=task_agent_state.id, \n",
    "    role=\"user\", \n",
    "    message=\"complete your tasks\"\n",
    ")\n",
    "nb_print(response.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "356e2cb1-a89a-4e56-8bed-1aabfd92bb09",
   "metadata": {
    "height": 42
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Block(value='[]', limit=2000, name='tasks', template=False, label='tasks', description=None, metadata_={}, user_id=None, id='block-8835ca09-cbe9-4b69-a084-87496cd60046')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_core_memory(task_agent_state.id).get_block(\"tasks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70253b9-7737-4427-906a-69e69c964c8d",
   "metadata": {},
   "source": [
    "> copy the id='block-...' string, from the code cell above \"client.get_core_memory...\", and then paste into the code cell client.get_block('block-...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228ba181-b0bf-4f04-bf94-1e520caeafc3",
   "metadata": {
    "height": 42
   },
   "outputs": [],
   "source": [
    "client.get_block('cut_and_paste_id_from_above')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcc39c5-311d-446e-9562-fa88eb2a10d1",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d452213f-b977-4a88-ba56-726216a9d218",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
