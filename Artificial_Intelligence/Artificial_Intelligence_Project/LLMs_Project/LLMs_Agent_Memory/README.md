# ğŸ’» [LLMs as Operating Systems: Agent Memory](https://www.deeplearning.ai/short-courses/llms-as-operating-systems-agent-memory/)

Welcome to the "LLMs as Operating Systems: Agent Memory" course! ğŸ§  Learn how to build agents with long-term, persistent memory using **Letta**, an open-source framework for memory-enhanced LLM agents. This course is taught by **Charles Packer** and **Sarah Wooders**, co-founders of Letta, and is based on the innovative ideas presented in the MemGPT research paper.

## ğŸ“˜ Course Summary
This course equips you with the skills to create AI agents that manage and edit memory autonomously, optimizing context usage for real-world applications like research and HR. Learn how to leverage **Letta** to add persistent, long-term memory to your LLM agents, enabling advanced reasoning and adaptability.

### **What Youâ€™ll Learn**
1. ğŸ”„ **Agent Memory Management**: Build agents with self-editing memory, utilizing tool-calling and multi-step reasoning.
2. ğŸ› ï¸ **Using Letta Framework**: Explore Lettaâ€™s features for adding memory capabilities to LLMs, including core and archival memory.
3. ğŸ§© **MemGPT Concepts**: Understand the key ideas behind MemGPT, including two-tier memory systems and how agent states are converted into prompts.
4. ğŸ¤ **Multi-Agent Collaboration**: Learn to implement collaborative agents by sharing memory blocks and exchanging messages.

### **Practical Applications**
- ğŸ” **Conversation Memory Control**: Manage expanding conversations by summarizing and moving less relevant information to a searchable database, ensuring smooth context flow.
- ğŸ“‚ **Persistent Fact Storage**: Save and edit details like names, dates, and preferences for future interactions.
- ğŸ“‘ **Task-Specific Memory**: Develop agents capable of swapping context-relevant information in real-time from a database for tasks like research.

## ğŸ”‘ Key Points
- ğŸ§  **Enhanced Memory Management**: Use Letta to create agents with long-term, persistent memory and advanced reasoning capabilities.
- ğŸ“‹ **Efficient Context Optimization**: Optimize LLM context window usage to reduce costs and improve processing speed.
- ğŸ¤– **Collaboration Between Agents**: Enable multi-agent systems that share memory and collaborate seamlessly.

## ğŸ‘¨â€ğŸ« About the Instructors
- **Charles Packer**: Co-Founder of Letta and co-author of the MemGPT paper.  
- **Sarah Wooders**: Co-Founder of Letta and a leading expert in building memory-enhanced LLM applications.

ğŸ”— To enroll in the course or for more details, visit ğŸ“š [deeplearning.ai](https://www.deeplearning.ai/short-courses/).
